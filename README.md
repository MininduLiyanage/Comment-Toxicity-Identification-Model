# Comment-Toxicity-Identification-Model

This repository contains a machine learning model designed to evaluate the toxicity of comments. The model utilizes a Bidirectional LSTM architecture with embedding layers and dense layers for classification. It is trained on a [dataset](https://docs.google.com/spreadsheets/d/1IzhCtYOWbwsg9-cXLi8mD666JHtbuxIqH6AA7mCt6Kw/edit?usp=sharing) annotated for toxicity to predict whether comments contain harmful or offensive language.
